# -*- mode: org; org-export-babel-evaluate: nil -*-
#+TITLE: Emoji and Group Identity on Twitter
#+Author: Carl Colglazier, Zackary Allen
#+LaTeX_CLASS: acmart
#+LATEX_CLASS_OPTIONS: [format=manuscript, review=false, screen=true, authorversion=true, nonacm=true, authordraft=true]
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+options: toc:nil
#+LaTeX_HEADER: \usepackage{hyperref}
#+latex_header: \usepackage{coloremoji}
# #+LaTeX_HEADER: \usepackage[margin=1in]{geometry}
#+LaTeX_HEADER: \usepackage[backend=bibtex,sorting=none]{biblatex}
#+LaTeX_HEADER: \addbibresource{main.bib}  %% point at your bib file
#+PANDOC_OPTIONS: bibliography:main.bib

#+LaTeX: \begin{abstract}
We propose a measure for group identity on Twitter using emoji
displayed by users in their names. Viewing the use of emoji
as social phenomenon, we introduce methods for measuring...
#+LaTeX: \end{abstract}

* Background

#+INCLUDE: background.tex

* Method

#+INCLUDE: method.tex

** Research Questions


+ R1: Do users with emojis connect more often with other emoji users? (computational)
+ R2: Do people tend to form cliques with similar emoji users? What does the overall network look like? (social)
+ R3: Are some emoji more likely to appear in cliques than others? (computational)

** Challenges
+  Data scraping and how much data is enough (10k users?) sparsity?
  (computational)
+ Connection representation (computational)
+ Understanding Twitter cliques (social)
+ R3 may change if there aren‚Äôt enough cliques

* Results
** Sample Analysis
#+BEGIN_SRC python :dir ./scripts :session :exports none :results silent
import numpy as np
import pandas as pd
from scipy import stats
from scrape_emoji import emoji_list
from itertools import chain
import math
import statsmodels
import statsmodels.api as sm
from statsmodels.formula.api import ols
from collections import Counter
from matplotlib import pyplot as plt
import numpy as np
import seaborn as sns
users = pd.read_csv("../data/users.csv", engine='c', lineterminator='\n')
original_sample = pd.read_csv("../data/sample.csv")
original_control = pd.read_csv("../data/control.csv")
updated = pd.read_csv("../data/updatedsamplecontrol.csv", lineterminator='\n')
meta = pd.read_csv("../data/meta.csv", lineterminator='\n')
meta["nemoji"] = meta["nemoji"].map(eval)
def get_emoji(text):
    s = set()
    t = text
    for e in em:
        if e in t:
            s.add(e)
            t = t.replace(e, '')
        if len(t) == 0:
            break
    return s

em = list(emoji_list())
em.sort(key=len, reverse=True)
updated["name_emoji"] = [get_emoji(str(x)) for x in updated["name"]]
sample = updated[(updated["name_emoji"].str.len() > 0) & (updated.index.isin(original_sample.index))]
sample = sample.sample(1000, random_state=31415926)
control = updated[(updated["name_emoji"].str.len() == 0) & (updated.index.isin(original_control.index))]
control = control.sample(1000, random_state=31415926)
#+END_SRC

Before any analysis, we must first determine if parametric statistics
apply. We can test for the normalcy of the distribution using
D‚ÄôAgostino and Pearson‚Äôs test for departure from normalcy.

#+BEGIN_SRC python :session :exports results :results values table
  t = {"sample": sample, "control": control}
  counts = ["listed_count", "followers_count", "friends_count"]
  results = []
  for key in t.keys():
    for count in counts:
      statistic, p = stats.normaltest(t[key][count])
      print(p)
      results.append({
        "Group": "{} {}".format(key, count),
        "statistic": statistic,
        "p-value": '%.2E' % p
      })
  
  series = pd.DataFrame(results)
  [list(series)] + [None] + series.round(4).values.tolist()
#+END_SRC

#+NAME: normaltest
#+CAPTION: D‚ÄôAgostino and Pearson‚Äôs test on variables.
#+RESULTS:
| Group                   |   p-value | statistic |
|-------------------------+-----------+-----------|
| sample listed_count     | 3.66E-295 | 1355.9307 |
| sample followers_count  | 1.31E-291 | 1339.5606 |
| sample friends_count    |  0.00E+00 | 1483.7946 |
| control listed_count    |  0.00E+00 | 2114.8148 |
| control followers_count |  0.00E+00 | 1779.9979 |
| control friends_count   | 1.10E-248 | 1141.8983 |

As Table [[normaltest]] shows, the null hypothesis that each sample comes from a
normal distribution can be rejected. The Mann-Whitney rank test is
used instead to test the null hypothesis that it is equally likely
that a randomly selected value from one sample will be less than or
greater than a randomly selected value from a second sample.

#+BEGIN_SRC python :session :exports results :results values table
  t = {"sample": sample, "control": control}
  counts = ["listed_count", "followers_count", "friends_count"]
  results = []
  for count in counts:
    statistic, p = stats.mannwhitneyu(control[count], sample[count])
    print(p)
    results.append({
      "Variable": count,
      "statistic": statistic,
      "p-value": '%.2E' % p
    })
  
  series = pd.DataFrame(results)
  [list(series)] + [None] + series.round(4).values.tolist()
#+END_SRC

#+NAME: tbl:mann
#+CAPTION: Mann-Whitney rank tests.
#+RESULTS:
| Variable        |  p-value | statistic |
|-----------------+----------+-----------|
| listed_count    | 4.23E-02 |  478001.5 |
| followers_count | 5.39E-23 |  373393.5 |
| friends_count   | 7.99E-16 |  397093.0 |

Table [[tbl:mann]] suggests a statistically significant different in the
distributions between the sample and control groups for the number of
lists in which users appear, the number of accounts users follow, and
the number of followers for each user.

#+BEGIN_SRC python :session :var f="vios.pdf" :results file graphics :exports results
plt.clf()
all_sampled["listed_count_rank"] = all_sampled["listed_count"].rank()
all_sampled["followers_count_rank"] = all_sampled["followers_count"].rank()
all_sampled["friends_count_rank"] = all_sampled["friends_count"].rank()
objs = ["listed_count_rank", "followers_count_rank", "friends_count_rank"]
fig, axes = plt.subplots(3, 1, figsize=(6, 8), sharex=True)
sns.violinplot(y="listed_count_rank", x="sample", data=all_sampled, ax=axes[0])
sns.violinplot(y="followers_count_rank", x="sample", data=all_sampled, ax=axes[1])
sns.violinplot(y="friends_count_rank", x="sample", data=all_sampled, ax=axes[2])
plt.savefig("../images/%s" % f)
"images/%s" % f
#+END_SRC

#+NAME: fig:vios
#+CAPTION: Violin plot.
#+RESULTS:
[[file:images/vios.pdf]]

Figure [[fig:vios]] shows the distribution of the ranks for the variables.

*** Old data. Not for export.                                      :noexport:

#+BEGIN_SRC python :session :var f="cum_listed.pdf" :results file graphics :exports none :eval no
plt.style.use('ggplot')
plt.clf()
bins = np.linspace(0, 250, 25)
plt.hist([control["listed_count"], sample["listed_count"]], bins, label=['control', 'sample'], cumulative=True)
plt.legend(loc='upper right')
plt.yscale('log', nonposy='clip')
plt.savefig("../images/%s" % f)
"images/%s" % f
#+END_SRC

#+ATTR_LATEX: :float multicolumn
#+RESULTS:
[[file:images/cum_listed.pdf]]

#+BEGIN_SRC python :session :var f="vio_listed.pdf" :results file graphics :exports none :eval no
sample["sample"] = True
control["sample"] = False
all_sampled = sample.append(control)
plt.clf()
ax = sns.violinplot(y="listed_count", x="sample", data=all_sampled)
plt.yscale('log', nonposy='clip')
plt.savefig("../images/%s" % f)
"images/%s" % f
#+END_SRC

#+ATTR_LATEX: :float multicolumn
#+RESULTS:
[[file:images/vio_listed.pdf]]

#+BEGIN_SRC python :session :exports none :results values table :eval no
statistic, pvalue = stats.mannwhitneyu(control["followers_count"], sample["followers_count"])
series = pd.DataFrame({"Statistic": [statistic], "p-value": [pvalue]})
[list(series)] + [None] + series.round(4).values.tolist()
#+END_SRC

#+CAPTION: Mann-Whitney rank test for the "followers count" variable.
#+RESULTS:
| Statistic | p-value |
|-----------+---------|
|  373393.5 |     0.0 |

#+BEGIN_SRC python :session :var f="cum_followers.pdf" :results file graphics :exports none :eval no
plt.style.use('ggplot')
plt.clf()
bins = np.linspace(0, 50_000, 25)
plt.hist([control["followers_count"], sample["followers_count"]], bins, label=['control', 'sample'], cumulative=True)
plt.legend(loc='upper left')
plt.yscale('log', nonposy='clip')
plt.savefig("../images/%s" % f)
"images/%s" % f
#+END_SRC

#+ATTR_LATEX: :float multicolumn
#+RESULTS:
[[file:images/cum_followers.pdf]]

#+BEGIN_SRC python :session :var f="vio_followers.pdf" :results file graphics :exports none :eval no
plt.clf()
ax = sns.violinplot(y="followers_count", x="sample", data=all_sampled)
plt.yscale('log', nonposy='clip')
plt.savefig("../images/%s" % f)
"images/%s" % f
#+END_SRC

#+ATTR_LATEX: :float multicolumn
#+RESULTS:
[[file:images/vio_followers.pdf]]

#+BEGIN_SRC python :session :exports none :results values table :eval no
statistic, pvalue = stats.mannwhitneyu(control["friends_count"], sample["friends_count"])
series = pd.DataFrame({"Statistic": [statistic], "p-value": [pvalue]})
[list(series)] + [None] + series.round(4).values.tolist()
#+END_SRC

#+CAPTION: Mann-Whitney rank test for the "friends count" (following) variable.
#+RESULTS:
| Statistic | p-value |
|-----------+---------|
|  397093.0 |     0.0 |


#+BEGIN_SRC python :session :var f="cum_friends.pdf" :results file graphics :exports none :eval no
plt.style.use('ggplot')
plt.clf()
bins = np.linspace(0, 50_000, 25)
plt.hist([control["friends_count"], sample["friends_count"]], bins, label=['control', 'sample'], cumulative=True)
plt.legend(loc='upper left')
plt.yscale('log', nonposy='clip')
plt.savefig("../images/%s" % f)
"images/%s" % f
#+END_SRC

#+ATTR_LATEX: :float multicolumn
#+RESULTS:
[[file:images/cum_friends.pdf]]

#+BEGIN_SRC python :session :var f="vio_friends.pdf" :results file graphics :exports none :eval no
plt.clf()
ax = sns.violinplot(y="friends_count", x="sample", data=all_sampled)
plt.yscale('log', nonposy='clip')
plt.savefig("../images/%s" % f)
"images/%s" % f
#+END_SRC

#+ATTR_LATEX: :float multicolumn
#+RESULTS:
[[file:images/vio_friends.pdf]]

** Network Analysis
#+BEGIN_SRC python :session :exports results :results output table
sample_follower_ids = set(chain.from_iterable([x.split(',') for x in list(sample.merge(original_sample, on="id", how='left')["followers"]) if type(x) == str]))
control_follower_ids = set(chain.from_iterable([x.split(',') for x in list(control.merge(original_control, on="id", how='left')["followers"]) if type(x) == str]))
meta["sample_follower"] = meta["id"].isin(sample_follower_ids)
meta["control_follower"] = meta["id"].isin(control_follower_ids)
c = Counter()
csample = Counter()
ccontrol = Counter()
for item in meta["nemoji"]:
    for e in item:
        c[e] += 1

for item in meta[meta["sample_follower"]]["nemoji"]:
    for e in item:
        csample[e] += 1

for item in meta[meta["control_follower"]]["nemoji"]:
    for e in item:
        ccontrol[e] += 1

most_common = [x[0] for x in c.most_common(10)]
print([["Emoji", "Total Count", "Sample Followers", "Control Followers"]] + [None] + [[x, c.get(x), csample.get(x), ccontrol.get(x)] for x in most_common])
#+END_SRC

#+RESULTS:
| Emoji | Total Count | Sample Followers | Control Followers |
|-------+-------------+------------------+-------------------|
| ‚ú®    |       26895 |             7743 |              2210 |
| üá∫üá∏    |       24072 |            15350 |              8901 |
| üëë    |       12985 |             3824 |              1163 |
| ‚ùå    |       11830 |             8596 |              4874 |
| üåπ    |       11396 |             3897 |              1529 |
| üåä    |       10740 |             6892 |              4896 |
| ‚ù§Ô∏è     |        9584 |             3444 |              1422 |
| üåª    |        7643 |             2250 |               845 |
| üéÑ    |        7417 |             1955 |               923 |
| üíú    |        7371 |             2189 |               484 |

#+BEGIN_SRC python :session :exports results :results output table
sample_following_ids = set(chain.from_iterable([x.split(',') for x in list(sample.merge(original_sample, on="id", how='left')["following"]) if type(x) == str]))
control_following_ids = set(chain.from_iterable([x.split(',') for x in list(control.merge(original_control, on="id", how='left')["following"]) if type(x) == str]))
meta["sample_following"] = meta["id"].isin(control_following_ids)
meta["control_following"] = meta["id"].isin(control_following_ids)
c = Counter()
csample = Counter()
ccontrol = Counter()
for item in meta["nemoji"]:
    for e in item:
        c[e] += 1

for item in meta[meta["sample_following"]]["nemoji"]:
    for e in item:
        csample[e] += 1

for item in meta[meta["control_following"]]["nemoji"]:
    for e in item:
        ccontrol[e] += 1

most_common = [x[0] for x in c.most_common(10)]
print([["Emoji", "Total Count", "Sample Following", "Control Following"]] + [None] + [[x, c.get(x), csample.get(x), ccontrol.get(x)] for x in most_common])
#+END_SRC

#+RESULTS:
| Emoji | Total Count | Sample Friends | Control Friends |
|-------+-------------+----------------+-----------------|
| ‚ú®    |       26895 |           2386 |            2386 |
| üá∫üá∏    |       24072 |           8883 |            8883 |
| üëë    |       12985 |           1126 |            1126 |
| ‚ùå    |       11830 |           4784 |            4784 |
| üåπ    |       11396 |           1582 |            1582 |
| üåä    |       10740 |           4876 |            4876 |
| ‚ù§Ô∏è     |        9584 |           1268 |            1268 |
| üåª    |        7643 |            892 |             892 |
| üéÑ    |        7417 |           1191 |            1191 |
| üíú    |        7371 |            494 |             494 |

#+BEGIN_SRC python :session :exports results :results values table
emoji_df = pd.DataFrame(0, index=emoji_list(), columns=emoji_list())
s = original_sample[original_sample["id"].isin(sample["id"])]
s["name_emoji"] = [get_emoji(str(x)) for x in s["name"]]
c = original_control[original_control["id"].isin(control["id"])]
for _, user in s[s.index < 10].iterrows():
    followers = [int(x) for x in user["followers"].split(",")]
    count = Counter()
    for emoji in meta[meta["id"].isin(followers)]["nemoji"]:
        for i, e in emoji:
            count[e] += 1
    for e in user["name_emoji"]:
        for em, value in count:
            print(e, em, value)
            emoji_df[e][em] += value

emoji_df.sum().sum()
#+END_SRC

#+RESULTS:
| 2 |

* Discussion
Users in our sample with an emoji in their display names follow more
users, have more followers, and are included in more lists.
** Limitations
The small sample size (N = 1000) limits the ability to compare
attributes between users with different kinds of emoji.
** Future Work
We were unable to answer R3 given the sample size. To do so
in the future.
#+BEGIN_EXPORT latex
\bibliographystyle{acm}
\printbibliography
#+END_EXPORT

